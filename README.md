# ğŸ§  Laboratorio 5: Algoritmos Voraces y TeorÃ­a de Juegos

## ğŸ“‹ DescripciÃ³n del Proyecto

Este laboratorio explora tres problemas fundamentales en inteligencia artificial y optimizaciÃ³n, demostrando diferentes enfoques algorÃ­tmicos para resolver problemas de toma de decisiones. Cada punto aborda un escenario especÃ­fico donde las estrategias "locales" pueden o no conducir a soluciones globalmente Ã³ptimas.

## ğŸ¯ Puntos del Laboratorio

#### 1. ğŸª‘ OrganizaciÃ³n de Sillas con Hill Climbing
#### 2. ğŸ’° Problema del Cambio de Monedas con Algoritmo Voraz
#### 3. ğŸ® Piedra, Papel o Tijera con Equilibrio de Nash

## ğŸª‘ Punto 1: OrganizaciÃ³n de Sillas con Hill Climbing

### ğŸ“‹ DescripciÃ³n

OptimizaciÃ³n de la disposiciÃ³n de 6 personas en sillas circulares maximizando la satisfacciÃ³n total mediante el algoritmo Hill Climbing.

#### ğŸ¯ Objetivo

Visualizar cÃ³mo pequeÃ±as modificaciones locales pueden mejorar una soluciÃ³n mediante bÃºsqueda iterativa.

### âš™ï¸ ImplementaciÃ³n

```python

import random

# Matriz de satisfacciÃ³n entre personas
satisfaction = [[0, 5, -2, 3, 1, 4],
                [5, 0, 3, -1, 2, 2],
                [-2, 3, 0, 4, -3, 5],
                [3, -1, 4, 0, 2, 1],
                [1, 2, -3, 2, 0, 4],
                [4, 2, 5, 1, 4, 0]]

def hill_climbing():
    current = list(range(6))
    random.shuffle(current)
    current_value = total_satisfaction(current)
    
    for _ in range(1000):
        i, j = random.sample(range(6), 2)
        neighbor = current[:]
        neighbor[i], neighbor[j] = neighbor[j], neighbor[i]
        neighbor_value = total_satisfaction(neighbor)
        if neighbor_value > current_value:
            current, current_value = neighbor, neighbor_value
    return current, current_value


```

### ğŸ“Š CaracterÃ­sticas

- Enfoque: BÃºsqueda local con mejoras incrementales

- Espacio de bÃºsqueda: 720 disposiciones posibles

- Vecindario: Intercambio de dos personas

- LimitaciÃ³n: Puede quedar atrapado en Ã³ptimos locales

## ğŸ’° Punto 2: Problema del Cambio de Monedas

### ğŸ“‹ DescripciÃ³n

Algoritmo voraz para dar cambio de $63 usando monedas de [50, 20, 10, 5, 1], minimizando la cantidad de monedas.

### ğŸ¯ Objetivo

Introducir el concepto de equilibrio y demostrar estrategias de selecciÃ³n local Ã³ptima.

### âš™ï¸ ImplementaciÃ³n

```python

def cambio_voraz(cantidad, monedas):
    resultado = {}
    for moneda in monedas:
        if cantidad >= moneda:
            num = cantidad // moneda
            cantidad -= num * moneda
            resultado[moneda] = num
    return resultado

monedas = [50, 20, 10, 5, 1]
cambio = cambio_voraz(63, monedas)

```
### ğŸ” Proceso para $63

- $50: 1 moneda â†’ Restante: $13

- $20: âŒ No aplica

- $10: 1 moneda â†’ Restante: $3

- $5: âŒ No aplica

- $1: 3 monedas â†’ Restante: $0

Resultado: 1Ã—$50 + 1Ã—$10 + 3Ã—$1 = 5 monedas

### ğŸ“ˆ AnÃ¡lisis

- Optimalidad: Ã“ptimo para sistemas canÃ³nicos de monedas

- Complejidad: O(n) donde n es nÃºmero de denominaciones

- LimitaciÃ³n: No Ã³ptimo para sistemas no canÃ³nicos


## ğŸ® Punto 3: Piedra, Papel o Tijera


### ğŸ“‹ DescripciÃ³n

ImplementaciÃ³n del equilibrio de Nash en el juego clÃ¡sico mediante estrategia mixta uniforme.

### ğŸ¯ Objetivo

Mostrar cÃ³mo la estrategia "siempre toma lo mejor ahora" puede o no llevar a la soluciÃ³n Ã³ptima en contextos adversariales.

### âš™ï¸ ImplementaciÃ³n

```python

import random

opciones = ["Piedra", "Papel", "Tijera"]

def estrategia_optima():
    return random.choice(opciones)  # DistribuciÃ³n uniforme 1/3

def jugar_ronda():
    jugador = estrategia_optima()
    oponente = estrategia_optima()
    # LÃ³gica de determinaciÃ³n del ganador

```

## ğŸ“Š Matriz de Pagos

### ğŸ² Reglas del Juego

```python
Piedra ğŸª¨ vs Tijera âœ‚ï¸  â†’ ğŸª¨ Gana
Papel ğŸ“„ vs Piedra ğŸª¨  â†’ ğŸ“„ Gana  
Tijera âœ‚ï¸ vs Papel ğŸ“„  â†’ âœ‚ï¸ Gana
Misma jugada â†’ Empate ğŸ¤

```

## ğŸ“ˆ RepresentaciÃ³n Matricial

```text
          Op: Piedra  Op: Papel  Op: Tijera
Yo: Piedra    Empate     Pierde      Gana
Yo: Papel      Gana      Empate     Pierde
Yo: Tijera    Pierde      Gana      Empate
```


## ğŸ§  TeorÃ­a de Juegos Aplicada

### âš–ï¸ Equilibrio de Nash

- Estrategia pura: No existe equilibrio (siempre hay contramedida)

- Estrategia mixta: DistribuciÃ³n uniforme 1/3 para cada opciÃ³n

- Valor esperado: 0 (empate a largo plazo contra oponente racional)

## ğŸ“ Fundamentos MatemÃ¡ticos


```python
# Probabilidades Ã³ptimas
prob_piedra = 1/3
prob_papel = 1/3  
prob_tijera = 1/3

# Valor esperado del juego
valor_esperado = 0  # Juego justo
```

## ğŸ¯ Estrategia del Algoritmo

### ğŸ”€ SelecciÃ³n Aleatoria Uniforme

```python
def estrategia_optima():
    return random.choice(["Piedra", "Papel", "Tijera"])
    # Equivalente a: random.choices(opciones, weights=[1/3, 1/3, 1/3])
```

## âœ… Por quÃ© es Ã“ptima

- Impredecibilidad: El oponente no puede anticipar la jugada

- ExplotaciÃ³n resistente: No hay patrones que el oponente pueda explotar

- MÃ¡ximo mÃ­nimo: Maximiza el peor caso posible (principio minimax)


## ğŸ“Š Resultados Esperados

```python

TÃº: Piedra  |  Oponente: Papel
âŒ Perdiste

TÃº: Tijera  |  Oponente: Papel  
ğŸ† Ganaste

TÃº: Papel  |  Oponente: Papel
ğŸ¤ Empate

TÃº: Papel  |  Oponente: Papel
ğŸ¤ Empate

TÃº: Tijera  |  Oponente: Papel
ğŸ† Ganaste

```

## âš¡ AnÃ¡lisis EstadÃ­stico
### ğŸ“Š DistribuciÃ³n a Largo Plazo

- Ganancias: â‰ˆ 33.3%

- PÃ©rdidas: â‰ˆ 33.3%

- Empates: â‰ˆ 33.3%

- Valor esperado: 0 puntos por ronda

### ğŸ² Ley de los Grandes NÃºmeros

```python

# DespuÃ©s de muchas rondas:
ganancias â‰ˆ 1/3
perdidas â‰ˆ 1/3
empates â‰ˆ 1/3
```

## ğŸ‘¥ Autores

#### ğŸ§‘â€ğŸ’» Contribuidores Principales

- **Carlos AndrÃ©s SuÃ¡rez Torres** â†’ [Carlos23Andres](https://github.com/Carlos23Andres)  

- **Saira Sharid Sanabria MuÃ±oz** â†’ [sharito202](https://github.com/sharito202)
